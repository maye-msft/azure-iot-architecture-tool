(function(e){function t(t){for(var r,n,i=t[0],c=t[1],u=t[2],d=0,p=[];d<i.length;d++)n=i[d],Object.prototype.hasOwnProperty.call(s,n)&&s[n]&&p.push(s[n][0]),s[n]=0;for(r in c)Object.prototype.hasOwnProperty.call(c,r)&&(e[r]=c[r]);l&&l(t);while(p.length)p.shift()();return o.push.apply(o,u||[]),a()}function a(){for(var e,t=0;t<o.length;t++){for(var a=o[t],r=!0,i=1;i<a.length;i++){var c=a[i];0!==s[c]&&(r=!1)}r&&(o.splice(t--,1),e=n(n.s=a[0]))}return e}var r={},s={app:0},o=[];function n(t){if(r[t])return r[t].exports;var a=r[t]={i:t,l:!1,exports:{}};return e[t].call(a.exports,a,a.exports,n),a.l=!0,a.exports}n.m=e,n.c=r,n.d=function(e,t,a){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:a})},n.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&"object"===typeof e&&e&&e.__esModule)return e;var a=Object.create(null);if(n.r(a),Object.defineProperty(a,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var r in e)n.d(a,r,function(t){return e[t]}.bind(null,r));return a},n.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return n.d(t,"a",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p="/";var i=window["webpackJsonp"]=window["webpackJsonp"]||[],c=i.push.bind(i);i.push=t,i=i.slice();for(var u=0;u<i.length;u++)t(i[u]);var l=c;o.push([0,"chunk-vendors"]),a()})({0:function(e,t,a){e.exports=a("56d7")},1:function(e,t){},2:function(e,t){},"2f0d":function(e,t,a){var r={"./locale":"c020","./locale.js":"c020"};function s(e){var t=o(e);return a(t)}function o(e){if(!a.o(r,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return r[e]}s.keys=function(){return Object.keys(r)},s.resolve=o,e.exports=s,s.id="2f0d"},3:function(e,t){},4:function(e,t){},"56d7":function(e,t,a){"use strict";a.r(t);a("e260"),a("e6cf"),a("cca6"),a("a79d");var r=a("2b0e"),s=function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("v-app",{staticStyle:{height:"100%"},attrs:{dark:""}},[a("v-app-bar",{attrs:{app:"",dense:"",color:"deep-purple",dark:""}},[a("v-toolbar-title",[e._v("Azure IoT Architecture Tool")]),a("v-spacer")],1),a("v-content",{staticStyle:{height:"100%"}},[a("Architecture")],1)],1)},o=[],n=function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("v-container",{staticStyle:{height:"100%"},attrs:{fluid:""}},[a("v-row",{staticStyle:{height:"100%"},attrs:{"no-gutters":""}},[a("v-col",{staticStyle:{height:"100%",overflow:"hidden"},attrs:{cols:"2"}},[a("v-card",{staticClass:"pa-2 mr-2",staticStyle:{height:"100%",overflow:"auto"},attrs:{outlined:"",tile:""}},[a("v-card-text",[a("div",[e._v("Requirements")])]),e._l(Object.keys(e.rules),(function(t,r){return[a("v-switch",{key:r,staticClass:"ma-2",attrs:{dense:"",label:t.replace(/_/g," ")},model:{value:e.acceptRules[t],callback:function(a){e.$set(e.acceptRules,t,a)},expression:"acceptRules[key]"}}),e._l(e.rules[t],(function(r,s){return[a("v-switch",{key:t+"-"+s,staticClass:"ma-2 pl-5",attrs:{label:"with "+r.replace(/_/g," ")},model:{value:e.acceptRules[t+"_"+r],callback:function(a){e.$set(e.acceptRules,t+"_"+r,a)},expression:"acceptRules[key+'_'+item]"}})]}))]}))],2)],1),a("v-col",{staticStyle:{height:"100%"},attrs:{cols:"10"}},[a("v-card",{staticStyle:{height:"100%",overflow:"auto"},attrs:{outlined:"",tile:""}},[a("v-card-text",[a("div",[e._v("Architecture Diagram")])]),a("v-card",{staticClass:"pa-2",staticStyle:{"text-align":"center","min-height":"500px","overflow-y":"hidden"}},[a("vue-mermaid",{staticStyle:{margin:"0",position:"absolute",top:"50%",left:"55%",transform:"translate(-50%, -50%)"},attrs:{nodes:e.imgData,type:"graph LR",config:e.mermaidConfig},on:{nodeClick:e.editNode}})],1),a("v-card",{staticClass:"mx-auto",staticStyle:{"text-align":"center",overflow:"auto"}},[a("v-simple-table",{scopedSlots:e._u([{key:"default",fn:function(){return[a("thead",[a("tr",[a("th",{staticClass:"text-left"},[e._v("Name")]),a("th",{staticClass:"text-left"},[e._v("Usage")]),a("th",{staticClass:"text-left"},[e._v("Cost Consideration")])])]),a("tbody",e._l(Object.keys(e.services),(function(t){return a("tr",{key:t},[a("td",{staticClass:"text-left"},[a("b",[a("a",{attrs:{target:"_blank",href:e.servicesinfo[t].link||"https://azure.microsoft.com/en-us/services/"+e.services[t].code}},[e._v(e._s(e.services[t].text))])])]),a("td",{staticClass:"text-left"},e._l(e.services[t].nextService,(function(r){return a("p",{key:r},[a("b",[e._v(e._s(e.services[r].text))]),a("br"),e.usage[t+"-"+r]?[e._v(" "+e._s(e.usage[t+"-"+r].description)+" "),a("a",{attrs:{target:"_blank",href:e.usage[t+"-"+r].link}},[e._v("more")])]:[e._v(e._s(t+"-"+r))]],2)})),0),a("td",{staticClass:"text-left"},[a("p",[a("ul",e._l(e.servicesinfo[t].costFactors,(function(t,r){return a("li",{key:r},[e._v(e._s(t))])})),0)]),a("b",{staticClass:"float-right"},[a("a",{attrs:{target:"_blank",href:e.servicesinfo[t].pricing||"https://azure.microsoft.com/en-us/pricing/details/"+e.services[t].code}},[e._v("Pricing")])])])])})),0)]},proxy:!0}])})],1)],1)],1)],1)],1)},i=[],c=(a("99af"),a("4160"),a("c975"),a("b64b"),a("ac1f"),a("5319"),a("159b"),a("6f00")),u=a.n(c),l=a("cdb4"),d={Data_Ingestion:["Device_Management"],Data_Storage:[],Realtime_Data_Analysis:["BigData"],Historical_Data_Analysis:["BigData","Distributed_NoSQL"],Predictive_and_Anormaly_Analysis:[],Data_Visualization:[],Data_API:[]},p={components:{},data:function(){return{rules:d,objects:l["OBJECTS"],acceptRules:{},data:[{id:1,text:"IoT Device",next:[2,"3"]},{id:2,text:"IoT Hub",next:["4",9,3]},{id:3,text:"Event Hub",next:["4","6",9,12]},{id:4,text:"Sream Analytcs",next:["5","6","8","7",12]},{id:5,text:"Azure SQL",next:["8"]},{id:6,text:"Azure Data Lake Storage",next:[10]},{id:7,text:"CosmosDB",next:[8]},{id:8,text:"Power BI",next:[]},{id:9,text:"Azure Databricks",next:[6]},{id:10,text:"Azure Machine Learning",next:[]},{id:11,text:"Azure Function",next:[12]},{id:12,text:"Azure Table Storage",next:[11,8]}],mermaidConfig:{theme:"forest"},usage:u.a,servicesinfo:l["OBJECTS"]}},computed:{services:function(){var e={},t={},a=1,r=this;return r.acceptRules&&Object.keys(r.objects).forEach((function(s){r.objects[s].rules&&r.objects[s].rules.forEach((function(o){Object.keys(r.acceptRules).forEach((function(n){o[n]&&r.acceptRules[n]&&(t[r.objects[s].layer]?0==n.indexOf(t[r.objects[s].layer].rule)?(e[s]={id:a,layer:r.objects[s].layer,text:s.replace(/_/g," "),fromLayer:o[n].from,rule:[n]},a++,0==n.indexOf(t[r.objects[s].layer].rule)&&t[r.objects[s].layer].service!=s&&(e[s].rule=e[s].rule.concat(e[t[r.objects[s].layer].service].rule),e[t[r.objects[s].layer].service]=null,delete e[t[r.objects[s].layer].service])):0!=t[r.objects[s].layer].rule.indexOf(n)&&(e[s]?o[n].from.forEach((function(t){-1==e[s].fromLayer.indexOf(t)&&(e[s].rule.push(n),e[s].fromLayer.push(t))})):(e[s]={id:a,layer:r.objects[s].layer,text:s.replace(/_/g," "),fromLayer:o[n].from,rule:[n]},a++)):(t[r.objects[s].layer]={service:s,rule:n},e[s]?o[n].from.forEach((function(t){-1==e[s].fromLayer.indexOf(t)&&(e[s].rule.push(n),e[s].fromLayer.push(t))})):e[s]={id:a,layer:r.objects[s].layer,text:s.replace(/_/g," "),fromLayer:o[n].from,rule:[n]},a++))}))}))})),Object.keys(e).forEach((function(t){e[t]["code"]=t.toLowerCase().replace(/_/g,"-"),e[t].fromLayer&&e[t].fromLayer.forEach((function(a){Object.keys(e).forEach((function(r){e[r].layer==a&&(e[r]["next"]=e[r]["next"]||[],e[r]["next"].push(e[t].id),e[r]["nextService"]=e[r]["nextService"]||[],e[r]["nextService"].push(t),e[r]["code"]=r.toLowerCase().replace(/_/g,"-"))}))}))})),e},imgData:function(){var e=this,t=[];return Object.keys(this.services).forEach((function(a){t.push(e.services[a])})),t}},methods:{editNode:function(e){alert(e)}}},m=p,f=a("2877"),g=a("6544"),_=a.n(g),h=a("b0af"),b=a("99d9"),y=a("62ad"),A=a("a523"),k=a("0fd9"),v=a("1f4f"),S=a("b73d"),D=Object(f["a"])(m,n,i,!1,null,null,null),z=D.exports;_()(D,{VCard:h["a"],VCardText:b["a"],VCol:y["a"],VContainer:A["a"],VRow:k["a"],VSimpleTable:v["a"],VSwitch:S["a"]});var L={name:"App",components:{Architecture:z},data:function(){return{}}},x=L,w=a("7496"),C=a("40dc"),I=a("a75b"),j=a("2fa4"),B=a("2a7f"),E=Object(f["a"])(x,s,o,!1,null,null,null),O=E.exports;_()(E,{VApp:w["a"],VAppBar:C["a"],VContent:I["a"],VSpacer:j["a"],VToolbarTitle:B["a"]});var M=a("f309");r["a"].use(M["a"]);var P=new M["a"]({}),Q=a("2857"),T=a.n(Q);r["a"].config.productionTip=!1,r["a"].use(T.a),new r["a"]({vuetify:P,render:function(e){return e(O)}}).$mount("#app")},"6f00":function(e,t){e.exports={"Azure_Data_Lake_Storage-Azure_Databricks_Spark":{link:"https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-quickstart-create-databricks-account?toc=%2fazure%2fstorage%2fblobs%2ftoc.json",description:"\n        Run Apache Spark jobs using Azure Databricks to perform analytics on data stored in a storage account"},"Event_Hubs-Azure_Data_Lake_Storage":{link:"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-archive-eventhub-capture",description:"Use Azure Data Lake Storage to capture data from Event Hubs"},"IoT_Hub-Azure_Data_Lake_Storage":{link:"https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-devguide-messages-d2c#azure-blob-storage",description:"IoT Hub can route messages to -- Azure Blob Storage and Azure Data Lake Storage Gen2 (ADLS Gen2) accounts. Azure Data Lake Storage accounts are hierarchical namespace-enabled storage accounts built on top of blob storage."},"IoT_Hub-Azure_Databricks_Structured_Streaming":{link:"https://docs.microsoft.com/en-us/azure/azure-databricks/databricks-stream-from-eventhubs",description:"Connect a data ingestion system with Azure Databricks to stream data into an Apache Spark cluster in near real-time. You set up data ingestion system using Azure Event Hubs and then connect it to Azure Databricks to process the messages coming through."},"Event_Hubs-Azure_Databricks_Structured_Streaming":{link:"https://docs.microsoft.com/en-us/azure/azure-databricks/databricks-stream-from-eventhubs",description:"Connect a data ingestion system with Azure Databricks to stream data into an Apache Spark cluster in near real-time. You set up data ingestion system using Azure Event Hubs and then connect it to Azure Databricks to process the messages coming through."},"Azure_Databricks_Structured_Streaming-Azure_Data_Lake_Storage":{link:"https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/azure-datalake-gen2",description:"Azure Databricks is an Apache Spark-based analytics platform optimized for the Microsoft Azure cloud services platform.\n        Azure Data Lake Storage Gen2 (also known as ADLS Gen2) is a next-generation data lake solution for big data analytics."},"Azure_Databricks_Structured_Streaming-SQL_Database":{link:"https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/sql-databases-azure",description:"The Spark connector for Azure SQL Database and SQL Server enables these databases to act as input data sources and output data sinks for Apache Spark jobs. It allows you to use real-time transactional data in big data analytics and persist results for ad-hoc queries or reporting."},"Azure_Databricks_Structured_Streaming-Cosmos_DB":{link:"https://docs.microsoft.com/en-us/azure/machine-learning/concept-data",description:"An Azure Machine Learning datastore keeps the connection information to your storage so you don't have to code it in your scripts."},"Azure_Data_Lake_Storage-Functions":{link:"https://github.com/Azure/azure-functions-datalake-extension",description:"Read and write data in Data Lake Storage with Azure Functions."},"SQL_Database-Functions":{link:"https://github.com/Azure/azure-functions-datalake-extension",description:"Use Azure Functions to create a scheduled job that connects to an Azure SQL Database or Azure SQL Managed Instance."},"Functions-SQL_Database":{link:"https://github.com/Azure/azure-functions-datalake-extension",description:"Use Azure Functions to create a scheduled job that connects to an Azure SQL Database or Azure SQL Managed Instance."},"Cosmos_DB-Functions":{link:"https://github.com/Azure/azure-functions-datalake-extension",description:"Azure Cosmos DB is a great way to store unstructured and JSON data. Combined with Azure Functions, Cosmos DB makes storing data quick and easy with much less code than required for storing data in a relational database."},"Functions-Cosmos_DB":{link:"https://github.com/Azure/azure-functions-datalake-extension",description:"Azure Cosmos DB is a great way to store unstructured and JSON data. Combined with Azure Functions, Cosmos DB makes storing data quick and easy with much less code than required for storing data in a relational database."},"Machine_Learning-Azure_Data_Lake_Storage":{link:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-access-data",description:"Azure Machine Learning supports accessing data from Azure Blob storage, Azure Files, Azure Data Lake Storage Gen1, Azure Data Lake Storage Gen2, Azure SQL Database, and Azure Database for PostgreSQL."},"Azure_Data_Lake_Storage-Machine_Learning":{link:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-access-data",description:"Azure Machine Learning supports accessing data from Azure Blob storage, Azure Files, Azure Data Lake Storage Gen1, Azure Data Lake Storage Gen2, Azure SQL Database, and Azure Database for PostgreSQL."},"Azure_Data_Lake_Storage-Power_BI":{link:"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-power-bi",description:"Use Power BI Desktop to analyze and visualize data stored in Azure Data Lake Storage and publish to PowerBI.com"},"Azure_Data_Lake_Storage-App_Service":{link:"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-power-bi",description:"Power BI Desktop to analyze and visualize data stored in Azure Data Lake Storage"},"Cosmos_DB-Power_BI":{link:"https://docs.microsoft.com/en-us/azure/cosmos-db/powerbi-visualize",description:"Connect Azure Cosmos DB account to Power BI Desktop. After connecting, you navigate to a collection, extract the data, transform the JSON data into tabular format, and publish a report to Power BI"},"Cosmos_DB-App_Service":{link:"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-power-bi",description:"With Cosmos DB SDK, it can work as backend database of Azure App services application."},"SQL_Database-App_Service":{link:"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-power-bi",description:"With Azure SQL drivers, it can work as backend database of Azure App services application."},"App_Service-API_Management":{link:"https://docs.microsoft.com/en-us/azure/api-management/import-api-app-as-api",description:"Azure API Management feature allows you to expose apps deployed in Azure App Service to manage, protect, and secure APIs"},"SQL_Database-Power_BI":{link:"https://docs.microsoft.com/en-us/power-bi/service-azure-sql-database-with-direct-connect",description:"Power BI can connect directly to Azure SQL Database and create reports that use live data. You can keep your data at the source and not in Power BI"},"Event_Hubs-Stream_Analytics":{link:"https://docs.microsoft.com/en-us/azure/event-hubs/process-data-azure-stream-analytics",description:"The Azure Stream Analytics service makes it easy to ingest, process, and analyze streaming data from Azure Event Hubs, enabling powerful insights to drive real-time actions. This integration allows you to quickly create a hot-path analytics pipeline"},"IoT_Hub-Stream_Analytics":{link:"https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-get-started-with-azure-stream-analytics-to-process-data-from-iot-devices",description:"The Azure Stream Analytics service makes it easy to ingest, process, and analyze streaming data from Azure Event Hubs, enabling powerful insights to drive real-time actions. This integration allows you to quickly create a hot-path analytics pipeline"},"Stream_Analytics-Azure_Data_Lake_Storage":{link:"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-stream-analytics",description:"Azure Data Lake Storage can be as an output for an Azure Stream Analytics job"},"Stream_Analytics-SQL_Database":{link:"https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-sql-output-perf",description:"SQL output in Azure Stream Analytics supports writing in parallel as an option. This option allows for fully parallel job topologies, where multiple output partitions are writing to the destination table in parallel. Enabling this option in Azure Stream Analytics however may not be sufficient to achieve higher throughputs, as it depends significantly on your SQL Azure database configuration and table schema. "},"Stream_Analytics-Cosmos_DB":{link:"https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-documentdb-output",description:"Azure Stream Analytics can target Azure Cosmos DB for JSON output, enabling data archiving and low-latency queries on unstructured JSON data. This document covers some best practices for implementing this configuration."}}},cdb4:function(e,t){var a={Devices:"Devices",EdgeDevices:"EdgeDevices",Data_Ingestion:"Data_Ingestion",Stream_Analysis:"Stream_Analysis",Data_Analysis:"Data_Analysis",BigData_Analysis:"BigData_Analysis",Machine_Learning:"Machine_Learning",Data_Storage:"Data_Storage",Data_Presentation:"Data_Presentation",Database:"Database",Database_NoSQL:"Database_NoSQL",Logic:"Logic",Application:"Application",API:"API"},r={IoT_Hub:{costFactors:["MESSAGES/DAY","MESSAGE METER SIZE"],layer:a.Data_Ingestion,rules:[{Data_Ingestion_Device_Management:{from:[a.Devices]}}]},Event_Hubs:{costFactors:["Throughput unit (1 MB/s ingress, 2 MB/s egress)","Ingress events"],layer:a.Data_Ingestion,rules:[{Data_Ingestion:{from:[a.Devices]}}]},Stream_Analytics:{costFactors:["vCore","RAM","Throughput"],layer:a.Stream_Analysis,rules:[{Realtime_Data_Analysis:{from:[a.Data_Ingestion]}}]},Azure_Databricks_Structured_Streaming:{costFactors:["vCore","RAM"],link:"https://azure.microsoft.com/en-us/services/databricks/",pricing:"https://azure.microsoft.com/en-us/pricing/details/databricks/",layer:a.Stream_Analysis,rules:[{Realtime_Data_Analysis_BigData:{from:[a.Data_Ingestion]}}]},Machine_Learning:{costFactors:["vCore","RAM"],layer:a.Machine_Learning,rules:[{Predictive_and_Anormaly_Analysis:{from:[a.Data_Storage]}}]},Azure_Data_Lake_Storage:{costFactors:["Storage","Transactions (Read/Write Operations)"],link:"https://azure.microsoft.com/en-us/services/storage/data-lake-storage/",pricing:"https://azure.microsoft.com/en-us/pricing/details/storage/data-lake/",layer:a.Data_Storage,rules:[{Data_Storage:{from:[a.Data_Ingestion,a.Stream_Analysis]}}]},Azure_Databricks_Spark:{costFactors:["vCore","RAM"],link:"https://azure.microsoft.com/en-us/services/databricks/",pricing:"https://azure.microsoft.com/en-us/pricing/details/databricks/",layer:a.BigData_Analysis,rules:[{Historical_Data_Analysis_BigData:{from:[a.Data_Storage]}}]},SQL_Database:{costFactors:["vCore","RAM","Storage"],layer:a.Database,rules:[{Historical_Data_Analysis:{from:[a.Stream_Analysis,a.Logic]}}]},Cosmos_DB:{costFactors:["Request Units per second (RU/s)","Item size","Item indexing","Item property count","Indexed properties","Data consistency","Query patterns","Query patterns"],layer:a.Database_NoSQL,rules:[{Historical_Data_Analysis_Distributed_NoSQL:{from:[a.Stream_Analysis,a.Logic]}}]},Functions:{costFactors:["vCore","RAM","Executions"],layer:a.Logic,rules:[{Historical_Data_Analysis:{from:[a.Database,a.Data_Storage]},Historical_Data_Analysis_Distributed_NoSQL:{from:[a.Database_NoSQL,a.Data_Storage]}}]},Power_BI:{costFactors:["Monthly price per user","Monthly price per dedicated cloud compute and storage resource"],link:"hhttps://powerbi.microsoft.com/en-us/power-bi-premium/",pricing:"https://powerbi.microsoft.com/en-us/pricing/",layer:a.Data_Presentation,rules:[{Data_Visualization:{from:[a.Database,a.Database_NoSQL,a.Data_Storage]}}]},App_Service:{costFactors:["vCore","RAM","Storage","Network Throughput"],layer:a.Application,rules:[{Data_API:{from:[a.Database,a.Database_NoSQL,a.Data_Storage]}}]},API_Management:{costFactors:["Hour"],layer:a.API,rules:[{Data_API:{from:[a.Application]}}]}};e.exports={OBJECTS:r,LAYER:a}}});
//# sourceMappingURL=app.7bae3a06.js.map